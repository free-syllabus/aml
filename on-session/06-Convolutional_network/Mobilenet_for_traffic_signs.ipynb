{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "df628ec2-881f-4af6-a200-43f9e5dd2350",
      "metadata": {
        "id": "df628ec2-881f-4af6-a200-43f9e5dd2350"
      },
      "source": [
        "# Using MobileNet to classify traffic signs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2579494c-95c5-4f40-aa43-ac6da24bb1f7",
      "metadata": {
        "id": "2579494c-95c5-4f40-aa43-ac6da24bb1f7"
      },
      "source": [
        "We will use [MobileNet](https://arxiv.org/abs/1704.04861) and fine-tune it to correctly classify a dataset of traffic signs.\n",
        "\n",
        "MobileNet is a small CNN originaly developed for mobile phones and other small devices to be fast and lightweight."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e9a560c-c820-4d5d-aa23-07f068d5b9c4",
      "metadata": {
        "id": "9e9a560c-c820-4d5d-aa23-07f068d5b9c4"
      },
      "source": [
        "--------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b94eda0-02dc-4581-a529-db91d912fc21",
      "metadata": {
        "id": "9b94eda0-02dc-4581-a529-db91d912fc21"
      },
      "source": [
        "Load necessary packages and libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "347a925c-74fd-4754-94c4-9a7c06a678b5",
      "metadata": {
        "id": "347a925c-74fd-4754-94c4-9a7c06a678b5"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from keras.models import Model\n",
        "from keras.applications import imagenet_utils\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.applications import MobileNet\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "from keras.utils import get_file, load_img, img_to_array\n",
        "import numpy as np\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load MobileNet"
      ],
      "metadata": {
        "id": "CL1tbJWymYqk"
      },
      "id": "CL1tbJWymYqk"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "567d5b51-dabd-4150-8208-96f6a4417156",
      "metadata": {
        "id": "567d5b51-dabd-4150-8208-96f6a4417156"
      },
      "outputs": [],
      "source": [
        "mobile = keras.applications.mobilenet.MobileNet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bb0fa416-32d2-41f5-8e25-73242c6c3403",
      "metadata": {
        "id": "bb0fa416-32d2-41f5-8e25-73242c6c3403"
      },
      "outputs": [],
      "source": [
        "def prepare_image(file):\n",
        "    img = load_img(file, target_size=(224, 224))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
        "    return keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00221d4e-0a68-4fc8-ac7f-04faafa3fa31",
      "metadata": {
        "id": "00221d4e-0a68-4fc8-ac7f-04faafa3fa31"
      },
      "source": [
        "## Testing MobileNet on dog images"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c987bed-7cf8-46d4-a521-5ef6d982b4d6",
      "metadata": {
        "id": "2c987bed-7cf8-46d4-a521-5ef6d982b4d6"
      },
      "source": [
        "Let's try some tests on images of different dog breeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5692a12-0ed7-4c89-8c2f-2bf836a5d88d",
      "metadata": {
        "id": "b5692a12-0ed7-4c89-8c2f-2bf836a5d88d"
      },
      "outputs": [],
      "source": [
        "Image(data='https://upload.wikimedia.org/wikipedia/commons/4/4f/German-shepherd-4040871920._%282%29.jpg') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fdaa6cc-7cb5-4a10-9f8a-48ad65bae49f",
      "metadata": {
        "id": "9fdaa6cc-7cb5-4a10-9f8a-48ad65bae49f"
      },
      "outputs": [],
      "source": [
        "preprocessed_image = prepare_image(get_file('German-shepperd.jpg',origin='https://upload.wikimedia.org/wikipedia/commons/4/4f/German-shepherd-4040871920._%282%29.jpg'))\n",
        "predictions = mobile.predict(preprocessed_image)\n",
        "results = imagenet_utils.decode_predictions(predictions)\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e54331f-c59c-4b1d-97b3-5607f03271c3",
      "metadata": {
        "id": "7e54331f-c59c-4b1d-97b3-5607f03271c3"
      },
      "outputs": [],
      "source": [
        "Image(data='https://upload.wikimedia.org/wikipedia/commons/d/d4/Labrador_Retriever_-_Yellow.JPG')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be29bc1a-ef1a-46b6-b085-f241e9ee7eb5",
      "metadata": {
        "id": "be29bc1a-ef1a-46b6-b085-f241e9ee7eb5"
      },
      "outputs": [],
      "source": [
        "preprocessed_image = prepare_image(get_file('Labrador.jpg',origin='https://upload.wikimedia.org/wikipedia/commons/d/d4/Labrador_Retriever_-_Yellow.JPG'))\n",
        "predictions = mobile.predict(preprocessed_image)\n",
        "results = imagenet_utils.decode_predictions(predictions)\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "415f8549-2302-4ff0-aae3-01972fe71a5b",
      "metadata": {
        "id": "415f8549-2302-4ff0-aae3-01972fe71a5b"
      },
      "source": [
        "It works pretty well, you can try here some different pictures if you're curious."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "622980b1-da53-4b50-b77f-3806e01b09b8",
      "metadata": {
        "id": "622980b1-da53-4b50-b77f-3806e01b09b8"
      },
      "source": [
        "## TODO - test on Traffic signs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b1f3a37-c016-4410-8475-493d39713296",
      "metadata": {
        "id": "8b1f3a37-c016-4410-8475-493d39713296"
      },
      "source": [
        "Now let's test the network on some images of traffic signs. We will work with `Stop`, `Speedlimit` and `Crosswalk`.\n",
        "Please use the code above as a template and try to find some images of the traffic signs and test the network on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1ee67eac-0f88-4108-9e9b-c74c6f7242ed",
      "metadata": {
        "id": "1ee67eac-0f88-4108-9e9b-c74c6f7242ed"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f34e7b9c-7a12-4ed1-adc0-8da02263a1db",
      "metadata": {
        "id": "f34e7b9c-7a12-4ed1-adc0-8da02263a1db"
      },
      "source": [
        "## Create traffic sign dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa0dff87-a647-40dc-9eb1-a6b83fe68f5a",
      "metadata": {
        "id": "aa0dff87-a647-40dc-9eb1-a6b83fe68f5a"
      },
      "source": [
        "Lets now manipulate MobileNet top few layers and employ transfer learning. To do this, we need to train it on some images. We will train it on `Stop`, `Speedlimit` and `Crosswalk` traffic signs. But instead of manually downloading images of them, let's use Google Image Search and pull the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "580264d5-51e4-49fc-b195-f7ff5b011cfc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "580264d5-51e4-49fc-b195-f7ff5b011cfc",
        "outputId": "07f04aa3-a73a-4552-ac55-302cfe82426e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting simple_image_download\n",
            "  Downloading simple_image_download-0.5-py3-none-any.whl (7.0 kB)\n",
            "  Downloading simple_image_download-0.4-py3-none-any.whl (4.9 kB)\n",
            "  Downloading simple_image_download-0.2-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from simple_image_download) (2.27.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->simple_image_download) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->simple_image_download) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->simple_image_download) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->simple_image_download) (3.4)\n",
            "Installing collected packages: simple_image_download\n",
            "Successfully installed simple_image_download-0.2\n"
          ]
        }
      ],
      "source": [
        "! pip install simple_image_download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b590c1dc-678b-4d56-bd18-2dfe00400ea8",
      "metadata": {
        "id": "b590c1dc-678b-4d56-bd18-2dfe00400ea8"
      },
      "outputs": [],
      "source": [
        "from simple_image_download import simple_image_download as simp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "866d85ee-8828-46ac-ad92-f68667a7c859",
      "metadata": {
        "id": "866d85ee-8828-46ac-ad92-f68667a7c859"
      },
      "outputs": [],
      "source": [
        "response = simp.simple_image_download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f194d96-2c72-4d69-a67a-442b4d852b91",
      "metadata": {
        "id": "5f194d96-2c72-4d69-a67a-442b4d852b91"
      },
      "outputs": [],
      "source": [
        "response().download('stop traffic sign', 150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0601e1d-6a6e-4c2f-9638-2c11a245dfb2",
      "metadata": {
        "id": "a0601e1d-6a6e-4c2f-9638-2c11a245dfb2"
      },
      "outputs": [],
      "source": [
        "response().download('maximum speed traffic sign', 150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "229cfbd4-5fc7-4f37-9c31-ca5137509662",
      "metadata": {
        "id": "229cfbd4-5fc7-4f37-9c31-ca5137509662"
      },
      "outputs": [],
      "source": [
        "response().download('crosswalk traffic sign', 150)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dce8b548-f343-4cc0-ac11-852e134bee85",
      "metadata": {
        "id": "dce8b548-f343-4cc0-ac11-852e134bee85"
      },
      "source": [
        "Check size of the images and remove the ones with low quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "5b25c9aa-b013-402a-8b4b-42914132db77",
      "metadata": {
        "id": "5b25c9aa-b013-402a-8b4b-42914132db77"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def check_pictures(directory):\n",
        "    for filename in os.listdir(directory):\n",
        "        f = os.path.join(directory, filename)\n",
        "        try:\n",
        "            img = Image.open(f)\n",
        "            wid, hgt = img.size\n",
        "            if wid < 300 or hgt < 300:\n",
        "                os.remove(f)\n",
        "        except:\n",
        "            os.remove(f)\n",
        "        \n",
        "\n",
        "            \n",
        "check_pictures(\"simple_images/stop traffic sign\")\n",
        "check_pictures(\"simple_images/maximum speed traffic sign\")\n",
        "check_pictures(\"simple_images/crosswalk traffic sign\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1350e74c-49b6-4f2d-9dec-444ffd5a2f9f",
      "metadata": {
        "id": "1350e74c-49b6-4f2d-9dec-444ffd5a2f9f"
      },
      "source": [
        "## Prepare model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65b13ef6-f6de-43ec-96eb-c1deb3c5ae73",
      "metadata": {
        "id": "65b13ef6-f6de-43ec-96eb-c1deb3c5ae73"
      },
      "source": [
        "Let's now use MobileNet, freeze the base layers and let's add and train the top few layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d278e24-7329-4a88-83c4-218fe04f0971",
      "metadata": {
        "id": "1d278e24-7329-4a88-83c4-218fe04f0971"
      },
      "outputs": [],
      "source": [
        "base_model = MobileNet(weights='imagenet',include_top=False) # imports the mobilenet model and discards the last layer.\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024,activation='relu')(x) # we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x = Dense(1024,activation='relu')(x) # dense layer 2\n",
        "x = Dense(512,activation='relu')(x) # dense layer 3\n",
        "preds = Dense(3,activation='softmax')(x) # final layer with softmax activation (this gives us probability), 3 outputs for 3 labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "945af540-0e7a-42b8-aed6-23eb77a02987",
      "metadata": {
        "id": "945af540-0e7a-42b8-aed6-23eb77a02987"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs=base_model.input,outputs=preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "605a03e1-1dac-4857-986f-efcca9305e84",
      "metadata": {
        "id": "605a03e1-1dac-4857-986f-efcca9305e84"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "151a4763-4d26-45e8-91db-0c8c23a1110a",
      "metadata": {
        "id": "151a4763-4d26-45e8-91db-0c8c23a1110a"
      },
      "source": [
        "We will use pre-trained weights as the model has been trained already on the ImageNet dataset. We ensure all the weights are non-trainable, we will only train the last few layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "7d820818-ace7-4b24-9f0a-0e32cb622ef9",
      "metadata": {
        "id": "7d820818-ace7-4b24-9f0a-0e32cb622ef9"
      },
      "outputs": [],
      "source": [
        "for layer in model.layers[:80]:\n",
        "    layer.trainable = False\n",
        "for layer in model.layers[80:]:\n",
        "    layer.trainable = True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7ad8e7d-3a6a-44d7-a142-68959d100ae9",
      "metadata": {
        "id": "e7ad8e7d-3a6a-44d7-a142-68959d100ae9"
      },
      "source": [
        "Now lets load the training data into the ImageDataGenerator. Specify path, and it automatically sends the data for training in batches, simplifying the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64c81712-8ede-4d52-ad76-7e626adb56f8",
      "metadata": {
        "id": "64c81712-8ede-4d52-ad76-7e626adb56f8"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(preprocessing_function=preprocess_input, validation_split=0.2)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_generator = datagen.flow_from_directory('simple_images',\n",
        "                                                 target_size=(224,224),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=batch_size,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True,\n",
        "                                                 subset='training')\n",
        "validation_generator = datagen.flow_from_directory('simple_images',\n",
        "                                                 target_size=(224,224),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=batch_size,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True,\n",
        "                                                 subset='validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05937318-c3b4-434c-85cd-db905546eba8",
      "metadata": {
        "id": "05937318-c3b4-434c-85cd-db905546eba8"
      },
      "source": [
        "Now let's do the real training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b133b948-53d1-40a8-80d4-4f0fc9a2c469",
      "metadata": {
        "id": "b133b948-53d1-40a8-80d4-4f0fc9a2c469"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(train_generator,\n",
        "                    steps_per_epoch=train_generator.n // batch_size,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=validation_generator.n // batch_size,\n",
        "                    epochs=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO test the model"
      ],
      "metadata": {
        "id": "V5BpGQxqosO-"
      },
      "id": "V5BpGQxqosO-"
    },
    {
      "cell_type": "markdown",
      "id": "c974e953-da0e-45e8-ad52-cf9cd41d3e0a",
      "metadata": {
        "id": "c974e953-da0e-45e8-ad52-cf9cd41d3e0a"
      },
      "source": [
        "Model is now trained. Now let's test some other input images to check the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "c2872c03-131e-4d03-8b28-d3705274f471",
      "metadata": {
        "id": "c2872c03-131e-4d03-8b28-d3705274f471"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e5f30cc-5a24-45ce-895f-10d8c1a028e2",
      "metadata": {
        "id": "8e5f30cc-5a24-45ce-895f-10d8c1a028e2"
      },
      "outputs": [],
      "source": [
        "# see which label corresponds to which class\n",
        "validation_generator.class_indices"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}